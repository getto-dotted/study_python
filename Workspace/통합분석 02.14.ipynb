{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('./csvfiles/mldata/tatanic_X_train.npy')\n",
    "y = np.load('./csvfiles/mldata/tatanic_y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =  train_test_split(x,y, test_size=0.15, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.80      0.81        75\n",
      "         1.0       0.75      0.78      0.77        59\n",
      "\n",
      "    accuracy                           0.79       134\n",
      "   macro avg       0.79      0.79      0.79       134\n",
      "weighted avg       0.79      0.79      0.79       134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.82        75\n",
      "         1.0       0.79      0.75      0.77        59\n",
      "\n",
      "    accuracy                           0.80       134\n",
      "   macro avg       0.80      0.79      0.79       134\n",
      "weighted avg       0.80      0.80      0.80       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(x_train, y_train)\n",
    "tree_pred = tree.predict(x_test)\n",
    "print(classification_report(y_test,tree_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.91      0.83        75\n",
      "         1.0       0.85      0.66      0.74        59\n",
      "\n",
      "    accuracy                           0.80       134\n",
      "   macro avg       0.81      0.78      0.79       134\n",
      "weighted avg       0.81      0.80      0.79       134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_pred = rfc.predict(x_test)\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.84      0.82        75\n",
      "         1.0       0.79      0.75      0.77        59\n",
      "\n",
      "    accuracy                           0.80       134\n",
      "   macro avg       0.80      0.79      0.79       134\n",
      "weighted avg       0.80      0.80      0.80       134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "log.fit(x_train, y_train)\n",
    "log_pred = tree.predict(x_test)\n",
    "print(classification_report(y_test,log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km= KMeans(n_clusters=2)\n",
    "km.fit(x_train)\n",
    "df = x_train\n",
    "df['label'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df1 = x_train\n",
    "df1['y'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x33543248>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df1.corr()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('./csvfiles/mldata/tatanic_X_train.npy')\n",
    "y = np.load('./csvfiles/mldata/tatanic_y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =  train_test_split(x,y, test_size=0.2, random_state=77) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clflog = LogisticRegression(random_state=1)\n",
    "clfdt = DecisionTreeClassifier(random_state=1)\n",
    "clfgn = GaussianNB()\n",
    "eclf_h = VotingClassifier(estimators=[('lr', clflog), ('rf', clfdt), ('gnb', clfgn)], voting='hard')\n",
    "eclf_s = VotingClassifier(estimators=[('lr', clflog), ('rf', clfdt), ('gnb', clfgn)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [clflog, clfdt, clfgn, eclf_h, eclf_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=1, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.8707865168539326\n",
      "====================\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=1, splitter='best')\n",
      "0.8314606741573034\n",
      "====================\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "0.7696629213483146\n",
      "====================\n",
      "VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=1, solver='warn',\n",
      "                                                 tol=0.0001, verbose=0,\n",
      "                                                 warm_start=False)),\n",
      "                             ('rf',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=1,\n",
      "                                                     splitter='best')),\n",
      "                             ('gnb',\n",
      "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "0.8595505617977528\n",
      "====================\n",
      "VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=1, solver='warn',\n",
      "                                                 tol=0.0001, verbose=0,\n",
      "                                                 warm_start=False)),\n",
      "                             ('rf',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=1,\n",
      "                                                     splitter='best')),\n",
      "                             ('gnb',\n",
      "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
      "                 weights=None)\n",
      "0.8651685393258427\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    score = model.score(x_test, y_test)\n",
    "    print(model)\n",
    "    print(score)\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('./csvfiles/mldata/tatanic_X_train.npy')\n",
    "y = np.load('./csvfiles/mldata/tatanic_y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test =  train_test_split(x,y, test_size=0.2, random_state=77) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clflog = LogisticRegression(random_state=1)\n",
    "clfdt = DecisionTreeClassifier(random_state=1)\n",
    "clfgn = GaussianNB()\n",
    "eclf_h = VotingClassifier(estimators=[('lr', clflog), ('rf', clfdt), ('gnb', clfgn)], voting='hard')\n",
    "eclf_s = VotingClassifier(estimators=[('lr', clflog), ('rf', clfdt), ('gnb', clfgn)], voting='soft')\n",
    "eclf_h1 = VotingClassifier(estimators=[('lr', clflog), ('rf', clfdt)], voting='hard')\n",
    "eclf_s1 = VotingClassifier(estimators=[('lr', clflog), ('rf', clfdt)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [clflog, clfdt, eclf_h, eclf_s,eclf_h1,eclf_s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=1, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "0.8707865168539326\n",
      "====================\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=1, splitter='best')\n",
      "0.8314606741573034\n",
      "====================\n",
      "VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=1, solver='warn',\n",
      "                                                 tol=0.0001, verbose=0,\n",
      "                                                 warm_start=False)),\n",
      "                             ('rf',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=1,\n",
      "                                                     splitter='best')),\n",
      "                             ('gnb',\n",
      "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "0.8595505617977528\n",
      "====================\n",
      "VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=1, solver='warn',\n",
      "                                                 tol=0.0001, verbose=0,\n",
      "                                                 warm_start=False)),\n",
      "                             ('rf',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=1,\n",
      "                                                     splitter='best')),\n",
      "                             ('gnb',\n",
      "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
      "                 weights=None)\n",
      "0.8651685393258427\n",
      "====================\n",
      "VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=1, solver='warn',\n",
      "                                                 tol=0.0001, verbose=0,\n",
      "                                                 warm_start=False)),\n",
      "                             ('rf',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=1,\n",
      "                                                     splitter='best'))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
      "                 weights=None)\n",
      "0.8539325842696629\n",
      "====================\n",
      "VotingClassifier(estimators=[('lr',\n",
      "                              LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                 dual=False, fit_intercept=True,\n",
      "                                                 intercept_scaling=1,\n",
      "                                                 l1_ratio=None, max_iter=100,\n",
      "                                                 multi_class='warn',\n",
      "                                                 n_jobs=None, penalty='l2',\n",
      "                                                 random_state=1, solver='warn',\n",
      "                                                 tol=0.0001, verbose=0,\n",
      "                                                 warm_start=False)),\n",
      "                             ('rf',\n",
      "                              DecisionTreeClassifier(class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=None,\n",
      "                                                     max_features=None,\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     presort=False,\n",
      "                                                     random_state=1,\n",
      "                                                     splitter='best'))],\n",
      "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
      "                 weights=None)\n",
      "0.8314606741573034\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    score = model.score(x_test, y_test)\n",
    "    print(model)\n",
    "    print(score)\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf_h1 = VotingClassifier(estimators=[('lr', clflog), ('dt', clfdt)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_param = [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]\n",
    "params = {'lr__solver':['liblinear'], 'lr__penalty':['l2'], 'lr__C':c_param,\n",
    "    'dt__criterion':['gini','entropy'],'dt__max_depth':[10,8,7,6,5,4,3,2],\n",
    "    'dt__min_samples_leaf':[1,2,3,4,5,6,7,8,9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=VotingClassifier(estimators=[('lr',\n",
       "                                                     LogisticRegression(C=1.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        dual=False,\n",
       "                                                                        fit_intercept=True,\n",
       "                                                                        intercept_scaling=1,\n",
       "                                                                        l1_ratio=None,\n",
       "                                                                        max_iter=100,\n",
       "                                                                        multi_class='warn',\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        penalty='l2',\n",
       "                                                                        random_state=1,\n",
       "                                                                        solver='warn',\n",
       "                                                                        tol=0.0001,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False)),\n",
       "                                                    ('dt',\n",
       "                                                     DecisionTreeClas...\n",
       "                                        voting='hard', weights=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'dt__criterion': ['gini', 'entropy'],\n",
       "                         'dt__max_depth': [10, 8, 7, 6, 5, 4, 3, 2],\n",
       "                         'dt__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'lr__C': [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0],\n",
       "                         'lr__penalty': ['l2'], 'lr__solver': ['liblinear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator= eclf_h1, param_grid=params, cv =5)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368495077355836"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__criterion': 'entropy',\n",
       " 'dt__max_depth': 6,\n",
       " 'dt__min_samples_leaf': 6,\n",
       " 'lr__C': 5.0,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.95      0.87        97\n",
      "         1.0       0.92      0.72      0.81        81\n",
      "\n",
      "    accuracy                           0.84       178\n",
      "   macro avg       0.86      0.83      0.84       178\n",
      "weighted avg       0.85      0.84      0.84       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, grid.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
